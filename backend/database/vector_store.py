"""
Vector Store - LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m embeddings vá»›i FAISS
"""
from config.config import config
import faiss
import numpy as np
import pickle
from typing import List, Dict, Tuple
from pathlib import Path
import sys

# ThÃªm path Ä‘á»ƒ import config
sys.path.append(str(Path(__file__).parent.parent.parent))


class VectorStore:
    """Class quáº£n lÃ½ vector database vá»›i FAISS"""

    def __init__(self, dimension: int, index_path: str = None):
        """
        Khá»Ÿi táº¡o Vector Store

        Args:
            dimension: Sá»‘ chiá»u cá»§a vector embeddings
            index_path: ÄÆ°á»ng dáº«n lÆ°u/load index
        """
        self.dimension = dimension
        self.index_path = index_path or str(
            config.VECTOR_STORE_DIR / "faiss_index")

        # Táº¡o FAISS index (IndexFlatL2 = tÃ¬m kiáº¿m chÃ­nh xÃ¡c)
        self.index = faiss.IndexFlatL2(dimension)

        # LÆ°u documents metadata
        self.documents = []

        print(f"âœ… Khá»Ÿi táº¡o Vector Store (dimension={dimension})")

    def add_documents(self, documents: List[Dict]):
        """
        ThÃªm documents vÃ o vector store

        Args:
            documents: List[{'content': str, 'metadata': dict, 'embedding': np.ndarray}]
        """
        if not documents:
            print("âš ï¸  KhÃ´ng cÃ³ document nÃ o Ä‘á»ƒ thÃªm")
            return

        # Láº¥y embeddings
        embeddings = np.array([doc['embedding'] for doc in documents])

        # Kiá»ƒm tra dimension
        if embeddings.shape[1] != self.dimension:
            raise ValueError(
                f"Embedding dimension khÃ´ng khá»›p! "
                f"Expected {self.dimension}, got {embeddings.shape[1]}"
            )

        # ThÃªm vÃ o FAISS index
        self.index.add(embeddings.astype('float32'))

        # LÆ°u metadata
        for doc in documents:
            doc_copy = {
                'content': doc['content'],
                'metadata': doc.get('metadata', {})
            }
            self.documents.append(doc_copy)

        print(f"âœ… ÄÃ£ thÃªm {len(documents)} documents")
        print(f"ğŸ“Š Tá»•ng sá»‘ documents: {self.index.ntotal}")

    def search(
        self,
        query_embedding: np.ndarray,
        top_k: int = None
    ) -> List[Dict]:
        """
        TÃ¬m kiáº¿m documents tÆ°Æ¡ng tá»± vá»›i query

        Args:
            query_embedding: Vector embedding cá»§a cÃ¢u há»i
            top_k: Sá»‘ káº¿t quáº£ tráº£ vá»

        Returns:
            List[Dict]: Danh sÃ¡ch documents [{
                'content': str,
                'metadata': dict,
                'score': float,  # Khoáº£ng cÃ¡ch (cÃ ng nhá» cÃ ng giá»‘ng)
                'similarity': float  # Äá»™ tÆ°Æ¡ng Ä‘á»“ng (0-1)
            }]
        """
        if self.index.ntotal == 0:
            print("âš ï¸  Vector store trá»‘ng!")
            return []

        top_k = top_k or config.TOP_K_RETRIEVAL

        # Reshape query embedding
        query_vector = query_embedding.reshape(1, -1).astype('float32')

        # TÃ¬m kiáº¿m
        distances, indices = self.index.search(
            query_vector, min(top_k, self.index.ntotal))

        # Chuáº©n bá»‹ káº¿t quáº£
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.documents):
                doc = self.documents[idx].copy()
                distance = float(distances[0][i])

                # Chuyá»ƒn distance thÃ nh similarity score (0-1)
                # Distance cÃ ng nhá» -> similarity cÃ ng cao
                # Sá»­ dá»¥ng cÃ´ng thá»©c: similarity = 1 / (1 + distance)
                similarity = 1.0 / (1.0 + distance)

                doc['score'] = distance
                doc['similarity'] = similarity
                doc['rank'] = i + 1

                results.append(doc)

        return results

    def save(self, path: str = None):
        """
        LÆ°u vector store ra file

        Args:
            path: ÄÆ°á»ng dáº«n lÆ°u (khÃ´ng bao gá»“m extension)
        """
        save_path = path or self.index_path

        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)

        # LÆ°u FAISS index
        faiss.write_index(self.index, f"{save_path}.faiss")

        # LÆ°u documents metadata
        with open(f"{save_path}.pkl", 'wb') as f:
            pickle.dump({
                'documents': self.documents,
                'dimension': self.dimension
            }, f)

        print(f"âœ… ÄÃ£ lÆ°u vector store táº¡i: {save_path}")

    def load(self, path: str = None):
        """
        Load vector store tá»« file

        Args:
            path: ÄÆ°á»ng dáº«n load (khÃ´ng bao gá»“m extension)
        """
        load_path = path or self.index_path

        # Check file tá»“n táº¡i
        if not Path(f"{load_path}.faiss").exists():
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {load_path}.faiss")
            return False

        # Load FAISS index
        self.index = faiss.read_index(f"{load_path}.faiss")

        # Load documents metadata
        with open(f"{load_path}.pkl", 'rb') as f:
            data = pickle.load(f)
            self.documents = data['documents']
            self.dimension = data['dimension']

        print(f"âœ… ÄÃ£ load vector store: {self.index.ntotal} documents")
        return True

    def clear(self):
        """XÃ³a toÃ n bá»™ dá»¯ liá»‡u trong vector store"""
        self.index.reset()
        self.documents = []
        print("ğŸ—‘ï¸  ÄÃ£ xÃ³a toÃ n bá»™ vector store")

    def get_stats(self) -> Dict:
        """Láº¥y thá»‘ng kÃª vá» vector store"""
        return {
            'total_documents': self.index.ntotal,
            'dimension': self.dimension,
            'index_type': type(self.index).__name__,
            'is_trained': self.index.is_trained
        }


def demo_vector_store():
    """Demo chá»©c nÄƒng vector store"""
    print("=" * 60)
    print("DEMO - VECTOR STORE (FAISS)")
    print("=" * 60)

    # Import embedding model
    from backend.rag.embeddings import EmbeddingModel

    # Táº¡o embedding model
    print("\n1ï¸âƒ£  Táº¡o embedding model...")
    embedder = EmbeddingModel(use_vietnamese=False)  # DÃ¹ng model nháº¹ cho demo

    # Táº¡o vector store
    print(f"\n2ï¸âƒ£  Táº¡o vector store...")
    vector_store = VectorStore(dimension=embedder.embedding_dim)

    # Táº¡o documents máº«u
    print(f"\n3ï¸âƒ£  Chuáº©n bá»‹ documents...")
    texts = [
        "Cáº£m cÃºm lÃ  bá»‡nh do virus, cÃ³ triá»‡u chá»©ng sá»‘t vÃ  Ä‘au Ä‘áº§u",
        "ViÃªm amidan gÃ¢y Ä‘au há»ng, khÃ³ nuá»‘t, cáº§n uá»‘ng khÃ¡ng sinh",
        "Äau Ä‘áº§u cÃ³ thá»ƒ do cÄƒng tháº³ng, máº¥t ngá»§ hoáº·c thiáº¿u nÆ°á»›c",
        "Sá»‘t cao trÃªn 39 Ä‘á»™ cáº§n Ä‘i khÃ¡m bÃ¡c sÄ© ngay",
        "Uá»‘ng nhiá»u nÆ°á»›c giÃºp giáº£m triá»‡u chá»©ng cáº£m cÃºm",
        "Vitamin C tÄƒng cÆ°á»ng há»‡ miá»…n dá»‹ch phÃ²ng bá»‡nh",
        "Äau bá»¥ng cÃ³ thá»ƒ do viÃªm dáº¡ dÃ y hoáº·c ngá»™ Ä‘á»™c thá»±c pháº©m",
        "Nghá»‰ ngÆ¡i Ä‘á»§ giáº¥c giÃºp cÆ¡ thá»ƒ phá»¥c há»“i nhanh",
        "Rá»­a tay thÆ°á»ng xuyÃªn Ä‘á»ƒ phÃ²ng ngá»«a vi khuáº©n",
        "TiÃªm vaccine phÃ²ng cÃºm má»—i nÄƒm má»™t láº§n"
    ]

    documents = []
    for i, text in enumerate(texts, 1):
        documents.append({
            'content': text,
            'metadata': {
                'source': f'doc_{i}.txt',
                'topic': 'sá»©c khá»e',
                'id': i
            }
        })

    # Encode documents
    print(f"â³ Äang encode {len(documents)} documents...")
    documents = embedder.encode_documents(documents)

    # ThÃªm vÃ o vector store
    print(f"\n4ï¸âƒ£  ThÃªm documents vÃ o vector store...")
    vector_store.add_documents(documents)

    # Hiá»ƒn thá»‹ thá»‘ng kÃª
    stats = vector_store.get_stats()
    print(f"\nğŸ“Š Thá»‘ng kÃª:")
    for key, value in stats.items():
        print(f"  - {key}: {value}")

    # Test tÃ¬m kiáº¿m
    print(f"\n5ï¸âƒ£  TEST TÃŒM KIáº¾M")
    print("=" * 60)

    queries = [
        "LÃ m sao Ä‘á»ƒ chá»¯a cáº£m cÃºm?",
        "Äau Ä‘áº§u pháº£i lÃ m gÃ¬?",
        "CÃ¡ch phÃ²ng bá»‡nh hiá»‡u quáº£"
    ]

    for query in queries:
        print(f"\nâ“ CÃ¢u há»i: '{query}'")

        # Encode query
        query_embedding = embedder.encode_text(query)

        # TÃ¬m kiáº¿m
        results = vector_store.search(query_embedding, top_k=3)

        print(f"ğŸ” Top 3 káº¿t quáº£:")
        for result in results:
            print(f"\n  Rank #{result['rank']}:")
            print(f"  ğŸ“„ {result['content']}")
            print(f"  ğŸ“Š Similarity: {result['similarity']:.3f}")
            print(f"  ğŸ“Œ Source: {result['metadata']['source']}")

    # Test save/load
    print(f"\n6ï¸âƒ£  TEST SAVE/LOAD")
    print("=" * 60)

    save_path = str(config.VECTOR_STORE_DIR / "demo_index")
    vector_store.save(save_path)

    # Táº¡o vector store má»›i vÃ  load
    print(f"\nâ³ Táº¡o vector store má»›i vÃ  load...")
    new_vector_store = VectorStore(dimension=embedder.embedding_dim)
    new_vector_store.load(save_path)

    # Test search láº¡i
    query_embedding = embedder.encode_text("sá»‘t cao")
    results = new_vector_store.search(query_embedding, top_k=2)

    print(f"\nâœ… Test search sau khi load:")
    for result in results[:2]:
        print(
            f"  - {result['content'][:50]}... (sim: {result['similarity']:.3f})")

    print("\nâœ… Demo hoÃ n táº¥t!")


if __name__ == "__main__":
    demo_vector_store()
