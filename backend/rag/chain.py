"""
RAG Chain - Káº¿t há»£p Retrieval + Generation
"""
from config.config import config
from backend.utils.prompts import (
    HEALTH_CHATBOT_SYSTEM_PROMPT,
    RAG_PROMPT_TEMPLATE,
    GREETING_RESPONSES,
    FAREWELL_RESPONSES,
    format_context,
    format_sources,
    is_greeting,
    is_farewell,
    build_messages
)
from backend.api.groq_client import GroqClient
from backend.rag.retriever import RAGRetriever
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Generator
import random

# Import modules
sys.path.append(str(Path(__file__).parent.parent.parent))


class RAGChain:
    """RAG Chain káº¿t há»£p Retrieval vÃ  Generation"""

    def __init__(
        self,
        retriever: RAGRetriever = None,
        llm_client: GroqClient = None,
        top_k: int = None
    ):
        """
        Khá»Ÿi táº¡o RAG Chain

        Args:
            retriever: RAG Retriever instance
            llm_client: Groq Client instance  
            top_k: Sá»‘ documents retrieve
        """
        self.top_k = top_k or config.TOP_K_RETRIEVAL

        # Khá»Ÿi táº¡o retriever
        if retriever:
            self.retriever = retriever
        else:
            print("ğŸ”„ Khá»Ÿi táº¡o RAG Retriever...")
            self.retriever = RAGRetriever(top_k=self.top_k)

        # Khá»Ÿi táº¡o LLM client
        if llm_client:
            self.llm = llm_client
        else:
            print("ğŸ”„ Khá»Ÿi táº¡o Groq LLM...")
            self.llm = GroqClient()

        print(f"âœ… RAG Chain sáºµn sÃ ng!")

    def ask(
        self,
        question: str,
        chat_history: List[Tuple[str, str]] = None,
        return_sources: bool = True
    ) -> str:
        """
        Há»i Ä‘Ã¡p vá»›i RAG

        Args:
            question: CÃ¢u há»i
            chat_history: Lá»‹ch sá»­ chat [(user_msg, bot_msg), ...]
            return_sources: CÃ³ tráº£ vá» nguá»“n khÃ´ng

        Returns:
            str: CÃ¢u tráº£ lá»i
        """
        # Kiá»ƒm tra greeting/farewell
        if is_greeting(question):
            return random.choice(GREETING_RESPONSES)

        if is_farewell(question):
            return random.choice(FAREWELL_RESPONSES)

        # Retrieve relevant documents
        retrieved_docs = self.retriever.retrieve(question, top_k=self.top_k)

        # Format context
        context = format_context(retrieved_docs)

        # Build messages
        messages = build_messages(
            question=question,
            context=context,
            system_prompt=HEALTH_CHATBOT_SYSTEM_PROMPT,
            chat_history=chat_history
        )

        # Generate answer
        answer = self.llm.chat(messages)

        # ThÃªm nguá»“n náº¿u cáº§n
        if return_sources and retrieved_docs:
            sources = format_sources(retrieved_docs)
            if sources and "ğŸ“š Nguá»“n:" not in answer:
                answer += f"\n\nğŸ“š Nguá»“n: {sources}"

        return answer

    def ask_stream(
        self,
        question: str,
        chat_history: List[Tuple[str, str]] = None,
        return_sources: bool = True
    ) -> Generator[str, None, None]:
        """
        Há»i Ä‘Ã¡p vá»›i streaming response

        Args:
            question: CÃ¢u há»i
            chat_history: Lá»‹ch sá»­ chat
            return_sources: Tráº£ vá» nguá»“n

        Yields:
            str: Tá»«ng pháº§n cÃ¢u tráº£ lá»i
        """
        # Kiá»ƒm tra greeting/farewell
        if is_greeting(question):
            yield random.choice(GREETING_RESPONSES)
            return

        if is_farewell(question):
            yield random.choice(FAREWELL_RESPONSES)
            return

        # Retrieve
        retrieved_docs = self.retriever.retrieve(question, top_k=self.top_k)

        # Format context
        context = format_context(retrieved_docs)

        # Build messages
        messages = build_messages(
            question=question,
            context=context,
            system_prompt=HEALTH_CHATBOT_SYSTEM_PROMPT,
            chat_history=chat_history
        )

        # Stream response
        for chunk in self.llm.chat_stream(messages):
            yield chunk

        # ThÃªm nguá»“n
        if return_sources and retrieved_docs:
            sources = format_sources(retrieved_docs)
            if sources:
                yield f"\n\nğŸ“š Nguá»“n: {sources}"

    def get_relevant_info(self, question: str, top_k: int = None) -> List[Dict]:
        """
        Chá»‰ retrieve thÃ´ng tin, khÃ´ng generate

        Args:
            question: CÃ¢u há»i
            top_k: Sá»‘ documents

        Returns:
            List[Dict]: Documents liÃªn quan
        """
        k = top_k or self.top_k
        return self.retriever.retrieve(question, top_k=k)


class HealthChatbot:
    """Chatbot hoÃ n chá»‰nh vá»›i memory"""

    def __init__(self, rag_chain: RAGChain = None):
        """
        Khá»Ÿi táº¡o Chatbot

        Args:
            rag_chain: RAG Chain instance
        """
        if rag_chain:
            self.rag_chain = rag_chain
        else:
            print("ğŸš€ Äang khá»Ÿi táº¡o Health Chatbot...")
            self.rag_chain = RAGChain()

        # Chat history: [(user_msg, bot_msg), ...]
        self.chat_history = []

        # Max history turns
        self.max_history_turns = 5

        print(f"âœ… Health Chatbot sáºµn sÃ ng phá»¥c vá»¥!")

    def chat(self, user_message: str) -> str:
        """
        Chat vá»›i bot (cÃ³ lÆ°u history)

        Args:
            user_message: Tin nháº¯n tá»« user

        Returns:
            str: Pháº£n há»“i
        """
        # Generate response
        bot_response = self.rag_chain.ask(
            question=user_message,
            chat_history=self.chat_history,
            return_sources=True
        )

        # LÆ°u vÃ o history
        self.chat_history.append((user_message, bot_response))

        # Giá»›i háº¡n history
        if len(self.chat_history) > self.max_history_turns:
            self.chat_history = self.chat_history[-self.max_history_turns:]

        return bot_response

    def chat_stream(self, user_message: str) -> Generator[str, None, None]:
        """
        Chat vá»›i streaming response

        Args:
            user_message: Tin nháº¯n

        Yields:
            str: Tá»«ng pháº§n response
        """
        full_response = ""

        # Stream response
        for chunk in self.rag_chain.ask_stream(
            question=user_message,
            chat_history=self.chat_history,
            return_sources=True
        ):
            full_response += chunk
            yield chunk

        # LÆ°u history
        self.chat_history.append((user_message, full_response))

        # Giá»›i háº¡n
        if len(self.chat_history) > self.max_history_turns:
            self.chat_history = self.chat_history[-self.max_history_turns:]

    def clear_history(self):
        """XÃ³a lá»‹ch sá»­ chat"""
        self.chat_history = []
        print("ğŸ—‘ï¸  ÄÃ£ xÃ³a lá»‹ch sá»­ chat")

    def get_history(self) -> List[Tuple[str, str]]:
        """Láº¥y lá»‹ch sá»­ chat"""
        return self.chat_history.copy()


def demo_rag_chain():
    """Demo RAG Chain"""
    print("=" * 70)
    print("DEMO - RAG CHAIN")
    print("=" * 70)

    try:
        # Táº¡o RAG Chain
        rag_chain = RAGChain()

        # Test 1: Simple ask
        print("\n" + "=" * 70)
        print("TEST 1 - SIMPLE ASK")
        print("=" * 70)

        question = "Triá»‡u chá»©ng cáº£m cÃºm lÃ  gÃ¬?"
        print(f"\nâ“ CÃ¢u há»i: {question}")
        print(f"\nğŸ¤– Tráº£ lá»i:")

        answer = rag_chain.ask(question)
        print(answer)

        # Test 2: Streaming
        print("\n" + "=" * 70)
        print("TEST 2 - STREAMING")
        print("=" * 70)

        question = "Äau Ä‘áº§u kÃ©o dÃ i nÃªn lÃ m gÃ¬?"
        print(f"\nâ“ CÃ¢u há»i: {question}")
        print(f"\nğŸ¤– Tráº£ lá»i (streaming):")

        for chunk in rag_chain.ask_stream(question):
            print(chunk, end='', flush=True)

        print("\n")

        # Test 3: Chatbot vá»›i history
        print("\n" + "=" * 70)
        print("TEST 3 - CHATBOT Vá»šI MEMORY")
        print("=" * 70)

        chatbot = HealthChatbot(rag_chain)

        conversation = [
            "Xin chÃ o!",
            "TÃ´i bá»‹ sá»‘t vÃ  Ä‘au Ä‘áº§u",
            "TÃ´i nÃªn lÃ m gÃ¬?",
            "Khi nÃ o cáº§n Ä‘i bÃ¡c sÄ©?",
            "Cáº£m Æ¡n nhÃ©!"
        ]

        for user_msg in conversation:
            print(f"\nğŸ‘¤ User: {user_msg}")
            bot_response = chatbot.chat(user_msg)
            print(f"ğŸ¤– Bot: {bot_response}")

        print(f"\nğŸ“Š Lá»‹ch sá»­: {len(chatbot.get_history())} turns")

        print("\nâœ… Demo hoÃ n táº¥t!")

    except ValueError as e:
        print(f"\n{e}")


if __name__ == "__main__":
    demo_rag_chain()
